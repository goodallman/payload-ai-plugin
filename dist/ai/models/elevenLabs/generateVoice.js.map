{"version":3,"sources":["../../../../src/ai/models/elevenLabs/generateVoice.ts"],"sourcesContent":["import { ElevenLabsClient } from 'elevenlabs'\r\n\r\ntype ElevenLabsTextToSpeechOptions = {\r\n  voice_id: string\r\n}\r\n\r\nexport const generateVoice = async (text: string, options: ElevenLabsTextToSpeechOptions) => {\r\n  const elevenLabs = new ElevenLabsClient({\r\n    apiKey: process.env.ELEVENLABS_API_KEY,\r\n  })\r\n  const response = (await elevenLabs.textToSpeech.convertWithTimstamps(options.voice_id, {\r\n    ...options,\r\n    text,\r\n  })) as {\r\n    alignment: string[]\r\n    audio_base64: string\r\n  }\r\n  if (response?.audio_base64) {\r\n    const audioBuffer = Buffer.from(response.audio_base64, 'base64')\r\n    // const transcript = convertToTranscript(mp3Audio.alignment)\r\n\r\n    return {\r\n      alignment: response.alignment,\r\n      buffer: audioBuffer,\r\n    }\r\n  }\r\n}\r\n"],"names":["ElevenLabsClient","generateVoice","text","options","elevenLabs","apiKey","process","env","ELEVENLABS_API_KEY","response","textToSpeech","convertWithTimstamps","voice_id","audio_base64","audioBuffer","Buffer","from","alignment","buffer"],"mappings":"AAAA,SAASA,gBAAgB,QAAQ,aAAY;AAM7C,OAAO,MAAMC,gBAAgB,OAAOC,MAAcC;IAChD,MAAMC,aAAa,IAAIJ,iBAAiB;QACtCK,QAAQC,QAAQC,GAAG,CAACC,kBAAkB;IACxC;IACA,MAAMC,WAAY,MAAML,WAAWM,YAAY,CAACC,oBAAoB,CAACR,QAAQS,QAAQ,EAAE;QACrF,GAAGT,OAAO;QACVD;IACF;IAIA,IAAIO,UAAUI,cAAc;QAC1B,MAAMC,cAAcC,OAAOC,IAAI,CAACP,SAASI,YAAY,EAAE;QACvD,6DAA6D;QAE7D,OAAO;YACLI,WAAWR,SAASQ,SAAS;YAC7BC,QAAQJ;QACV;IACF;AACF,EAAC"}